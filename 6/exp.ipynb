{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTVqdxzmp2TJ"
   },
   "source": [
    "- Sequential - Framework for NN\n",
    "- Dense - Fully connected layer with weights in each neuron\n",
    "- Input - Input layer\n",
    "- Flatten - Convert n-D data to 1-D\n",
    "- Activation - Activation layers. They just apply a function to the input.\n",
    "- Mnist - Dataset with handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "47D762jCdD-X"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MJJxKNBfdQ0v",
    "outputId": "77ecfd94-6c72-4e87-c35e-571dc5c8464f"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"all_japanese_stocks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1301</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1003.504517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1301</td>\n",
       "      <td>2001-01-02</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1003.504517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1301</td>\n",
       "      <td>2001-01-03</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1003.504517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1301</td>\n",
       "      <td>2001-01-04</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>19300.0</td>\n",
       "      <td>996.336853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1301</td>\n",
       "      <td>2001-01-05</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>19700.0</td>\n",
       "      <td>953.329529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date    High     Low    Open   Close   Volume  \\\n",
       "0        1301  2001-01-01  1400.0  1400.0  1400.0  1400.0      0.0   \n",
       "1        1301  2001-01-02  1400.0  1400.0  1400.0  1400.0      0.0   \n",
       "2        1301  2001-01-03  1400.0  1400.0  1400.0  1400.0      0.0   \n",
       "3        1301  2001-01-04  1420.0  1370.0  1420.0  1390.0  19300.0   \n",
       "4        1301  2001-01-05  1400.0  1330.0  1390.0  1330.0  19700.0   \n",
       "\n",
       "     Adj Close  \n",
       "0  1003.504517  \n",
       "1  1003.504517  \n",
       "2  1003.504517  \n",
       "3   996.336853  \n",
       "4   953.329529  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['Date'] = (data['Date'] - data['Date'].min()).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[[\"High\", \"Low\", \"Open\", \"Close\", \"Adj Close\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "BD3iwePWd4Mx"
   },
   "outputs": [],
   "source": [
    "input_dim = len(x.columns)\n",
    "model = Sequential([\n",
    "        # Encoder\n",
    "        Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(16, activation='relu'),  # Bottleneck layer\n",
    "        \n",
    "        # Decoder\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(input_dim)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "wFQ0jP0LeDuu"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = x.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = tf.convert_to_tensor(x_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Nbgw-haeQk-",
    "outputId": "b31de902-08d4-4f24-a9a3-81bea267ae78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 1409726.2500 - accuracy: 0.4600\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 52733.0156 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 2589.4966 - accuracy: 0.7050 \n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 523.9653 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 436.0072 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 432.8030 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 432.7235 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 434.6611 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 437.2708 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 434.3069 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 433.4580 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 432.3187 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 432.8880 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 434.4776 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 431.3683 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 432.4636 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 432.3756 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 434.7855 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 431.5231 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 431.4181 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 433.2780 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 436.1924 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 432.0057 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 433.2765 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 435.9406 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 433.8413 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 440.9502 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 432.9568 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 431.6904 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 434.6364 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 433.7925 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 432.4926 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 433.3402 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 434.3251 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 433.1669 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 429.7484 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 437.2374 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 430.6990 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 433.5688 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 433.3419 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 432.2888 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 436.9101 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 432.1235 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 434.1938 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 436.3689 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 434.5661 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 432.8590 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 433.2890 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 435.0008 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 437.5598 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 433.5817 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 431.0623 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 446.1494 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 434.5685 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 440.0912 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 442.1987 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 437.2039 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 439.7112 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 434.7914 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 446.7481 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 434.1181 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 436.3680 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 430.4951 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 429.8834 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 426.4063 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 440.3207 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 435.4963 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 429.7714 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 428.3407 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 433.2397 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 432.5490 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 430.1801 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 434.0252 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 434.6667 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 431.2455 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 426.4883 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 433.3052 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 435.0352 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 427.4586 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 427.1051 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 432.8040 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 423.1770 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 423.4609 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 431.6691 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 424.9120 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 426.1763 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 427.8434 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 434.5717 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 438.2396 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 422.1013 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 426.7679 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 438.4140 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 433.7049 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 426.9444 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 429.8108 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 429.1986 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 423.7548 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 441.3118 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 419.8516 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 443.4564 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a60a072210>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_tensor, x_tensor, epochs=100, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ChxXBgZieWb9",
    "outputId": "5d0067ff-f77b-471d-a504-977de1963b83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out = model.predict(x_tensor)\n",
    "test_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "pmTv6dgWepcl"
   },
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "losses = loss_fn(x_tensor, test_out)\n",
    "\n",
    "normal = np.percentile(losses, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly = losses[losses > normal]\n",
    "len(anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
